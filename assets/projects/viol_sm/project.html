<!-- Meta info row -->
<div style="display: flex; flex-wrap: wrap; margin-bottom: 1rem; align-items: center;">
  <!-- Published date -->
  <p style="color: grey; padding: 0rem 1rem; margin: 0;">
    <i>Published on September 20, 2020 <a href="https://ceur-ws.org/Vol-3202/davincis-paper4.pdf" target="_blank">[Paper]</a></i> 
  </p>

  <!-- TL;DR centered -->
  <div class="tldr-container">
    <div class="tldr-box">
      <!-- TL;DR text -->
      <div class="tldr-text">
        <span>TL;DR</span>
        <span>AI-generated audio summary</span>
      </div>

      <!-- Audio player -->
      <audio controls class="tldr-audio">
        <source src="../assets/projects/viol_sm/viol_summary.m4a" type="audio/mpeg">
        Your browser does not support the audio element.
      </audio>
    </div>
  </div>
</div>


<!-- Content -->
<p>
  This project was developed as part of the <strong>DA-VINCIS shared task</strong>, a challenge focused on 
  detecting and classifying mentions of violent events in Spanish-language tweets. The task 
  included two subtasks: the first asked whether a tweet mentions a violent incident, while 
  the second required identifying the specific type of violent event, such as accidents, 
  thefts, kidnappings, or homicides. Interestingly, Subtask 1 can be seen as a simplification 
  of Subtask 2, focusing only on separating Non-violent tweets from the rest. With this in mind, 
  we designed our models to tackle Subtask 2 directly, then derived Subtask 1's output through 
  post-processing.
</p>

<p>
  To address the problem, we developed two main system architectures:
</p>

<ul>
  <li>
    <strong>1-step system:</strong> a single multi-label classifier predicts all categories—Non-violent, 
    Accident, Theft, Kidnap, and Homicide—in one pass.
  </li>
  <li><strong>2-step system:</strong> a two-pass approach where a binary classifier first filters 
    out non-violent tweets, followed by a multi-label classifier that assigns the finer-grained 
    labels to violent tweets.
  </li>
</ul>

<figure style="text-align: center; margin: 2em 0;">
  <img src="../assets/projects/viol_sm/methodology.png" alt="Methodology overview" style="width: 80%; height: auto;">
  <figcaption style="font-size: 0.9em; color: #555; margin-top: 0.5em;">
    Methodology overview. We propose two different systems: a single multi-label classifier, 
    and a two-pass approach where a binary classifier, followed by a multi-label classifier
    (see the <a href="https://ceur-ws.org/Vol-3202/davincis-paper4.pdf" target="_blank">article</a>
    for more details).
  </figcaption>
</figure>

<p>
  All classifiers were based on <i>Transformer neural networks</i>, and we explored multiple variants 
  that differed in the choice of pre-trained language model and the training data used. We also 
  experimented with ensembles to combine predictions from different variants.
</p>

<p>
  To further improve performance and address the challenges posed by the dataset, we implemented 
  several strategies:
</p>

<ul>
  <li>
    <strong>Data augmentation:</strong> to tackle class imbalance and enrich the training set, 
    we applied techniques such as <i>back-translation</i>.
  </li>
  <li>
    <strong>Data relabeling:</strong> preliminary error analysis of our systems identified 
    inconsistencies in the corpus, which motivated us to develop a system for automatically 
    relabeling certain data samples.
  </li>
  <li>
    <strong>Keyword masking:</strong> applied during training to prevent overfitting to frequently 
    occurring expressions.
  </li>
</ul>

<p>
  These strategies helped the models generalize better to the noisy and diverse content of social 
  media posts. Ultimately, our approach proved highly effective. By using a unified system for 
  both subtasks, combined with careful data augmentation and keyword masking, our models achieved 
  <strong>second place in both subtasks</strong>, with <strong>F1-scores of 77.32 and 52.86</strong>, 
  respectively. 
</p>
