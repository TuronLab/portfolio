<!-- Meta info row -->
<div style="display: flex; flex-wrap: wrap; margin-bottom: 1rem; align-items: center;">
  <!-- Published date -->
  <p style="color: grey; padding: 0rem 1rem; margin: 0;">
    <i>Published on February 19, 2024 <a href="https://link.springer.com/chapter/10.1007/978-981-97-3289-0_45" target="_blank">[Paper]</a></i> 
  </p>

  <!-- TL;DR centered -->
   <div class="tldr-container">
    <div class="tldr-box">
      <!-- TL;DR text -->
      <div class="tldr-text">
        <span>TL;DR</span>
        <span>AI-generated audio summary</span>
      </div>

      <!-- Audio player -->
      <audio controls class="tldr-audio">
        <source src="assets/projects/email_clf/email_clf.m4a" type="audio/mpeg">
        Your browser does not support the audio element.
      </audio>
    </div>
  </div>

</div>


<!-- Content -->
<p>
  This project dives into the challenge of automatically classifying business emails 
  into five categories: <strong>Administrative, Commercial, Issues, Operations, and 
  Collections</strong>. We compared traditional statistical methods with modern large 
  language models (LLMs) and ChatGPT prompting techniques to see which approach handles 
  real-world email data best.
</p>

<p>
  Using a dataset of anonymized email conversations, we designed multiple pre-processing 
  strategies to clean noisy elements like repeated characters, reply headers, privacy 
  disclaimers, and URLs. Then we tested three main types of models:
</p>

<ul>
  <li><strong>SVM + TF-IDF:</strong> classic baseline;</li>
  <li><strong>BERT and BLOOM:</strong> fine-tuned LLMs;</li>
  <li><strong>ChatGPT zero-shot:</strong> with carefully crafted prompts.</li>
</ul>
<p>
  The experiments showed that traditional approaches can still outperform modern LLMs on 
  noisy, domain-specific email data. In particular, <strong>SVM with TF-IDF achieved the 
  highest overall performance</strong>, reaching an F1 score above 0.85. LLMs like BERT 
  and BLOOM, while powerful, struggled with the unstructured data, and ChatGPT performed 
  respectably in a zero-shot setup with a 0.71 F1 score.
</p>

<p>
  These results highlight that traditional models remain competitive for real-world 
  classification tasks, particularly when data is messy or unstructured. While SVMs 
  handle noise naturally, LLMs and ChatGPT benefit considerably from careful pre-processing.
</p>
